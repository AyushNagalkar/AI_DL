{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO72NBWxltRV",
        "outputId": "987bfae3-c2fd-4a80-f940-340756d7d9a0"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python tensorflow\n",
        "!pip install google.colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKOfrYjpyVBE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import base64\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "RvA6C9pnxu2a",
        "outputId": "998394ab-8d24-4494-f025-5b8dee74c277"
      },
      "outputs": [],
      "source": [
        "# JavaScript code to capture a photo using the webcam\n",
        "js_code = '''\n",
        "function initCamera() {\n",
        "    return new Promise((resolve, reject) => {\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'none';\n",
        "        document.body.appendChild(video);\n",
        "        const streamPromise = navigator.mediaDevices.getUserMedia({video: true});\n",
        "        streamPromise.then((stream) => {\n",
        "            video.srcObject = stream;\n",
        "            video.onloadedmetadata = () => {\n",
        "                resolve(video);\n",
        "            };\n",
        "            video.play();\n",
        "        }).catch((error) => {\n",
        "            reject(error);\n",
        "        });\n",
        "    });\n",
        "}\n",
        "\n",
        "async function takePhoto() {\n",
        "    const video = await initCamera();\n",
        "    const canvas = document.createElement('canvas');\n",
        "    canvas.width = video.videoWidth;\n",
        "    canvas.height = video.videoHeight;\n",
        "    const context = canvas.getContext('2d');\n",
        "    context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "    const img = canvas.toDataURL('image/jpeg');\n",
        "    return img;\n",
        "}\n",
        "'''\n",
        "\n",
        "display(Javascript(js_code))\n",
        "\n",
        "# Function to convert JavaScript captured image to OpenCV format\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = base64.b64decode(js_reply.split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(image_bytes))\n",
        "    image_np = np.array(image_PIL)\n",
        "    frame = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    return frame\n",
        "\n",
        "# Load the pre-trained face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "while True:\n",
        "    # Capture image using the webcam\n",
        "    js_reply = eval_js('takePhoto()')\n",
        "    frame = js_to_image(js_reply)\n",
        "\n",
        "    if frame is None:\n",
        "        continue\n",
        "\n",
        "    # Convert the image to grayscale for face detection\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    # Draw rectangles around detected faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
        "\n",
        "    # Display the image with detected faces\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Break the loop if 'Esc' key is pressed\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzbRE4OFyWk7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NagIGdop2YvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDlB4X8b2Yrv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLcfzc5j2ZLl"
      },
      "source": [
        "# **Face Detection Using Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qte40hYWyXJc",
        "outputId": "eb12184a-04e4-490e-ba24-213717d477a0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to your dataset\n",
        "dataset_path = '/content/data'\n",
        "class_names = ['happy', 'sad']  # replace with your class names\n",
        "\n",
        "# Initialize data and labels lists\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Load images\n",
        "for class_index, class_name in enumerate(class_names):\n",
        "    folder_path = os.path.join('data', class_name)\n",
        "    for image_name in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_name)\n",
        "        if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):  # Check for valid image formats\n",
        "            print(f\"Skipping non-image file: {image_name}\")\n",
        "            continue\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Failed to load image: {image_path}\")  # Print an error message\n",
        "            continue\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "        image = cv2.resize(image, (128, 128))  # Resize images to 128x128 pixels\n",
        "        data.append(image)\n",
        "        labels.append(class_index)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "data = np.array(data, dtype=\"float\") / 255.0  # Normalize pixel values\n",
        "data = np.expand_dims(data, axis=-1)  # Add a channel dimension\n",
        "labels = np.array(labels)\n",
        "\n",
        "# One-hot encode the labels\n",
        "labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "yzxNWIQf4gtB",
        "outputId": "6341cd85-3735-4b3c-eaf2-5c85776b1167"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(128, 128, 1), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation=\"softmax\"))  # For binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKq12-Qa4qwO",
        "outputId": "cdb0c85c-30fe-4223-fa91-d2b2c18eb1d8"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=15, batch_size=32)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('face_recognition_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpZIbEUZ5I4Y",
        "outputId": "9f54d200-a05a-4e38-c951-7452c68b38df"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(testX, testY)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqp8MoTt5J3-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load a single image and preprocess it\n",
        "image_path = '/content/Sad_Person.jpeg'\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "image = cv2.resize(image, (128, 128))\n",
        "image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
        "image = np.expand_dims(image, axis=0)   # Add batch dimension\n",
        "image = image.astype(\"float\") / 255.0   # Normalize pixel values\n",
        "\n",
        "# Predict the class\n",
        "prediction = model.predict(image)\n",
        "predicted_class = class_names[np.argmax(prediction)]\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "\n",
        "img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
